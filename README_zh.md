# LangChain AI SDK é€‚é…å™¨

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Development Status](https://img.shields.io/badge/status-alpha-orange.svg)](https://pypi.org/project/langchain-aisdk-adapter/)

> **âš ï¸ Alpha ç‰ˆæœ¬æé†’**: æœ¬é¡¹ç›®ç›®å‰å¤„äº alpha é˜¶æ®µã€‚è™½ç„¶æˆ‘ä»¬åŠªåŠ›ç¡®ä¿ç¨³å®šæ€§å’Œå¯é æ€§ï¼Œä½†è¯·æ³¨æ„ API å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä»åœ¨å¼€å‘ä¸­ã€‚æˆ‘ä»¬æ„Ÿè°¢æ‚¨çš„è€å¿ƒï¼Œå¹¶æ¬¢è¿ä»»ä½•åé¦ˆæ¥å¸®åŠ©æˆ‘ä»¬æ”¹è¿›ï¼

ç”¨äºè¿æ¥ LangChain/LangGraph åº”ç”¨ç¨‹åºä¸ AI SDK UI æµåè®®ã€‚è¿™ä¸ªåº“æ—¨åœ¨è®©å¼€å‘è€…æ›´å®¹æ˜“åœ°å°† LangChain çš„å¼ºå¤§åŠŸèƒ½ä¸ç°ä»£æµå¼æ¥å£é›†æˆã€‚

## âœ¨ ç‰¹æ€§

æˆ‘ä»¬åŠªåŠ›è®©è¿™ä¸ªé€‚é…å™¨å°½å¯èƒ½å…¨é¢å’Œç”¨æˆ·å‹å¥½ï¼š

- **ğŸ”„ å…¨é¢çš„åè®®æ”¯æŒ**: æ”¯æŒ 15+ AI SDK åè®®ï¼ŒåŒ…æ‹¬æ–‡æœ¬æµã€å·¥å…·äº¤äº’ã€æ­¥éª¤ç®¡ç†å’Œæ•°æ®å¤„ç†
- **âš™ï¸ æ™ºèƒ½é…ç½®**: çµæ´»çš„ `AdapterConfig` ç³»ç»Ÿè®©æ‚¨ç²¾ç¡®æ§åˆ¶ç”Ÿæˆå“ªäº›åè®®
- **ğŸ”’ çº¿ç¨‹å®‰å…¨çš„å¤šç”¨æˆ·æ”¯æŒ**: `ThreadSafeAdapterConfig` ä¸º Web åº”ç”¨ä¸­çš„å¹¶å‘è¯·æ±‚æä¾›éš”ç¦»çš„åè®®çŠ¶æ€
- **ğŸ›ï¸ åŠ¨æ€åè®®æ§åˆ¶**: ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯åœ¨æ‰§è¡ŒæœŸé—´ä¸´æ—¶å¯ç”¨/ç¦ç”¨ç‰¹å®šåè®®
- **ğŸ› ï¸ ä¸°å¯Œçš„å·¥å…·æ”¯æŒ**: ä¸ LangChain å·¥å…·ã€ä»£ç†å’Œå‡½æ•°è°ƒç”¨æ— ç¼é›†æˆ
- **ğŸ“Š ä½¿ç”¨è·Ÿè¸ª**: å†…ç½®çš„æµå¤„ç†ç»Ÿè®¡å’Œç›‘æ§åŠŸèƒ½
- **ğŸ”’ ç±»å‹å®‰å…¨**: å®Œæ•´çš„ Python ç±»å‹æç¤ºå’Œ Pydantic éªŒè¯
- **ğŸ­ å·¥å‚æ–¹æ³•**: åœ¨éœ€è¦æ—¶æä¾›ä¾¿æ·çš„å·¥å‚æ–¹æ³•è¿›è¡Œæ‰‹åŠ¨åè®®ç”Ÿæˆ
- **ğŸ”Œ å¯æ‰©å±•è®¾è®¡**: æ˜“äºæ‰©å±•å’Œå®šåˆ¶ä»¥é€‚åº”ç‰¹å®šç”¨ä¾‹

## ğŸš€ å¿«é€Ÿå¼€å§‹

æˆ‘ä»¬å¸Œæœ›è¿™èƒ½è®©æ‚¨å¿«é€Ÿä¸Šæ‰‹ï¼š

### å®‰è£…

**Alpha ç‰ˆæœ¬**: æ­¤åŒ…å·²åœ¨ Test PyPI ä¸Šå‘å¸ƒï¼Œä¾›æ—©æœŸæµ‹è¯•å’Œåé¦ˆä½¿ç”¨ã€‚

```bash
# ä» Test PyPI åŸºç¡€å®‰è£…
pip install --index-url https://test.pypi.org/simple/ langchain-aisdk-adapter

# åŒ…å«ç¤ºä¾‹ï¼ˆåŒ…æ‹¬ LangChainã€LangGraphã€OpenAIï¼‰
pip install --index-url https://test.pypi.org/simple/ langchain-aisdk-adapter[examples]

# åŒ…å« Web æ¡†æ¶æ”¯æŒï¼ˆåŒ…æ‹¬ FastAPIã€Uvicornï¼‰
pip install --index-url https://test.pypi.org/simple/ langchain-aisdk-adapter[web]

# å¼€å‘ç‰ˆæœ¬ï¼ˆåŒ…æ‹¬æµ‹è¯•å’Œä»£ç æ£€æŸ¥å·¥å…·ï¼‰
pip install --index-url https://test.pypi.org/simple/ langchain-aisdk-adapter[dev]
```

**æ³¨æ„**: ç”±äºè¿™æ˜¯ Test PyPI ä¸Šçš„ alpha ç‰ˆæœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å…ˆä»ä¸» PyPI å®‰è£…ä¾èµ–é¡¹ï¼š

```bash
# å…ˆå®‰è£…ä¾èµ–é¡¹ï¼Œç„¶åå®‰è£…åŒ…
pip install langchain-core langchain-openai pydantic
pip install --index-url https://test.pypi.org/simple/ langchain-aisdk-adapter
```

### åŸºç¡€ç”¨æ³•

è¿™é‡Œæ˜¯ä¸€ä¸ªç®€å•çš„å…¥é—¨ç¤ºä¾‹ï¼š

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_aisdk_adapter import LangChainAdapter

# åˆ›å»ºæ‚¨çš„ LangChain æ¨¡å‹
llm = ChatOpenAI(model="gpt-3.5-turbo", streaming=True)

# åˆ›å»ºæµ
stream = llm.astream([HumanMessage(content="ä½ å¥½ï¼Œä¸–ç•Œï¼")])

# è½¬æ¢ä¸º AI SDK æ ¼å¼ - å°±æ˜¯è¿™ä¹ˆç®€å•ï¼
ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)

# åœ¨æ‚¨çš„åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨
async for chunk in ai_sdk_stream:
    print(chunk, end="", flush=True)
```

### é…ç½®é€‰é¡¹

æˆ‘ä»¬åŒ…å«äº†å‡ ä¸ªé¢„è®¾é…ç½®æ¥ç®€åŒ–å¸¸è§ç”¨ä¾‹ï¼š

```python
from langchain_aisdk_adapter import LangChainAdapter, AdapterConfig, ThreadSafeAdapterConfig

# æœ€å°è¾“å‡º - ä»…åŸºæœ¬æ–‡æœ¬å’Œæ•°æ®
config = AdapterConfig.minimal()

# ä¸“æ³¨äºå·¥å…·äº¤äº’
config = AdapterConfig.tools_only()

# å¯ç”¨æ‰€æœ‰åŠŸèƒ½ï¼ˆé»˜è®¤ï¼‰
config = AdapterConfig.comprehensive()

# è‡ªå®šä¹‰é…ç½®
config = AdapterConfig(
    enable_text=True,
    enable_data=True,
    enable_tool_calls=True,
    enable_steps=False,  # ç¦ç”¨æ­¥éª¤è·Ÿè¸ª
    enable_reasoning=False  # ç¦ç”¨æ¨ç†è¾“å‡º
)

stream = LangChainAdapter.to_data_stream_response(your_stream, config=config)

# åè®®æš‚åœ/æ¢å¤åŠŸèƒ½
with config.pause_protocols(['0', '2']):  # ä¸´æ—¶ç¦ç”¨æ–‡æœ¬å’Œæ•°æ®åè®®
    # åœ¨æ­¤å—ä¸­ï¼Œä¸ä¼šç”Ÿæˆæ–‡æœ¬å’Œæ•°æ®åè®®
    restricted_stream = LangChainAdapter.to_data_stream_response(some_stream, config=config)
    async for chunk in restricted_stream:
        # åªä¼šå‘å‡ºå·¥å…·è°ƒç”¨ã€ç»“æœå’Œæ­¥éª¤
        print(chunk)
# ä¸Šä¸‹æ–‡ç»“æŸååè®®è‡ªåŠ¨æ¢å¤

# å¤šç”¨æˆ·åº”ç”¨çš„çº¿ç¨‹å®‰å…¨é…ç½®
safe_config = ThreadSafeAdapterConfig()

# æ¯ä¸ªè¯·æ±‚éƒ½æœ‰éš”ç¦»çš„åè®®çŠ¶æ€
with safe_config.protocols(['0', '9', 'a']):  # ä»…å¯ç”¨æ–‡æœ¬ã€å·¥å…·è°ƒç”¨å’Œç»“æœ
    stream = LangChainAdapter.to_data_stream_response(your_stream, config=safe_config)
    # æ­¤é…ç½®ä¸ä¼šå½±å“å…¶ä»–å¹¶å‘è¯·æ±‚
```

## ğŸ“‹ åè®®æ”¯æŒçŠ¶æ€

æˆ‘ä»¬å°†æ”¯æŒçš„åè®®åˆ†ä¸ºä¸‰ç±»ï¼Œå¸®åŠ©æ‚¨äº†è§£å¯ç”¨åŠŸèƒ½ä»¥åŠå®ƒä»¬çš„è§¦å‘æ¡ä»¶ï¼š

### ğŸŸ¢ è‡ªåŠ¨æ”¯æŒçš„åè®®

è¿™äº›åè®®ä¼šä» LangChain/LangGraph äº‹ä»¶ä¸­è‡ªåŠ¨ç”Ÿæˆï¼Œå…·æœ‰ç‰¹å®šçš„è§¦å‘æ¡ä»¶ï¼š

#### **`0:` (æ–‡æœ¬åè®®)**
**è§¦å‘æ¡ä»¶**: å½“ LLM äº§ç”Ÿæµå¼æ–‡æœ¬å†…å®¹æ—¶ç”Ÿæˆ
**æ ¼å¼**: `0:"æµå¼æ–‡æœ¬å†…å®¹"`
**å‘ç”Ÿæ—¶æœº**: 
- åœ¨ `llm.astream()` è°ƒç”¨æœŸé—´
- å½“ LangGraph èŠ‚ç‚¹äº§ç”Ÿæ–‡æœ¬è¾“å‡ºæ—¶
- ä»»ä½•æ¥è‡ªè¯­è¨€æ¨¡å‹çš„æµå¼æ–‡æœ¬

#### **`2:` (æ•°æ®åè®®)**
**è§¦å‘æ¡ä»¶**: ä¸ºç»“æ„åŒ–æ•°æ®å’Œå…ƒæ•°æ®ç”Ÿæˆ
**æ ¼å¼**: `2:[{"key":"value"}]`
**å‘ç”Ÿæ—¶æœº**:
- LangGraph èŠ‚ç‚¹å…ƒæ•°æ®å’Œä¸­é—´ç»“æœ
- å·¥å…·æ‰§è¡Œå…ƒæ•°æ®
- æ¥è‡ª LangChain å›è°ƒçš„è‡ªå®šä¹‰æ•°æ®

#### **`9:` (å·¥å…·è°ƒç”¨åè®®)**
**è§¦å‘æ¡ä»¶**: å½“å·¥å…·è¢«è°ƒç”¨æ—¶ç”Ÿæˆ
**æ ¼å¼**: `9:{"toolCallId":"call_123","toolName":"search","args":{"query":"test"}}`
**å‘ç”Ÿæ—¶æœº**:
- LangChain ä»£ç†å·¥å…·è°ƒç”¨
- LangGraph å·¥å…·èŠ‚ç‚¹æ‰§è¡Œ
- èŠå¤©æ¨¡å‹ä¸­çš„å‡½æ•°è°ƒç”¨

#### **`a:` (å·¥å…·ç»“æœåè®®)**
**è§¦å‘æ¡ä»¶**: å½“å·¥å…·æ‰§è¡Œå®Œæˆæ—¶ç”Ÿæˆ
**æ ¼å¼**: `a:{"toolCallId":"call_123","result":"å·¥å…·è¾“å‡º"}`
**å‘ç”Ÿæ—¶æœº**:
- å·¥å…·æ‰§è¡ŒæˆåŠŸå
- åœ¨ä»»ä½• `9:` åè®®ä¹‹å
- æˆåŠŸå’Œé”™è¯¯ç»“æœéƒ½ä¼šç”Ÿæˆ

#### **`b:` (å·¥å…·è°ƒç”¨æµå¼€å§‹åè®®)**
**è§¦å‘æ¡ä»¶**: åœ¨æµå¼å·¥å…·è°ƒç”¨å¼€å§‹æ—¶ç”Ÿæˆ
**æ ¼å¼**: `b:{"toolCallId":"call_123","toolName":"search"}`
**å‘ç”Ÿæ—¶æœº**:
- åœ¨å·¥å…·å‚æ•°æµå¼€å§‹ä¹‹å‰
- ä»…é€‚ç”¨äºæ”¯æŒæµå¼å‚æ•°çš„å·¥å…·

#### **`d:` (å®Œæˆæ¶ˆæ¯åè®®)** âš ï¸ **ä»…é™ LangGraph**
**è§¦å‘æ¡ä»¶**: **ä»…åœ¨ LangGraph å·¥ä½œæµä¸­**å½“æ¶ˆæ¯å®Œæˆæ—¶ç”Ÿæˆ
**æ ¼å¼**: `d:{"finishReason":"stop","usage":{"promptTokens":10,"completionTokens":20}}`
**å‘ç”Ÿæ—¶æœº**:
- **LangGraph å·¥ä½œæµæ¶ˆæ¯å®Œæˆ**
- **ä¸ä¼šåœ¨åŸºç¡€ LangChain æµä¸­ç”Ÿæˆ**
- LangGraph èŠ‚ç‚¹æ‰§è¡Œç»“æŸ
- åŒ…å«å¯ç”¨çš„ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯

#### **`e:` (å®Œæˆæ­¥éª¤åè®®)** ğŸ”„ **å¢å¼ºæ”¯æŒ**
**è§¦å‘æ¡ä»¶**: å½“ä¸»è¦å·¥ä½œæµç»„ä»¶å®Œæˆæ‰§è¡Œæ—¶ç”Ÿæˆ
**æ ¼å¼**: `e:{"stepId":"step_123","finishReason":"completed"}`
**å‘ç”Ÿæ—¶æœº**:
- **LangGraph å·¥ä½œæµæ­¥éª¤å®Œæˆ** (ä¸»è¦ç”¨ä¾‹)
- **LangChain ä»£ç†æ‰§è¡Œ** (AgentExecutor, ReActAgent, ChatAgent ç­‰)
- **åŸºäºé“¾çš„å·¥ä½œæµ** (LLMChain, SequentialChain, RouterChain ç­‰)
- **å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„ç»„ä»¶** (agent, chain, executor, workflow, multi_agent)
- å¤šæ­¥éª¤è¿‡ç¨‹å’Œæ¨ç†æ­¥éª¤çš„ç»“æŸ

#### **`f:` (å¼€å§‹æ­¥éª¤åè®®)** ğŸ”„ **å¢å¼ºæ”¯æŒ**
**è§¦å‘æ¡ä»¶**: å½“ä¸»è¦å·¥ä½œæµç»„ä»¶å¼€å§‹æ‰§è¡Œæ—¶ç”Ÿæˆ
**æ ¼å¼**: `f:{"stepId":"step_123","stepType":"agent_action"}`
**å‘ç”Ÿæ—¶æœº**:
- **LangGraph å·¥ä½œæµæ­¥éª¤å¼€å§‹** (ä¸»è¦ç”¨ä¾‹)
- **LangChain ä»£ç†æ‰§è¡Œ** (AgentExecutor, ReActAgent, ChatAgent ç­‰)
- **åŸºäºé“¾çš„å·¥ä½œæµ** (LLMChain, SequentialChain, RouterChain ç­‰)
- **LangGraph ç»„ä»¶** (LangGraph, CompiledGraph, StateGraph ç­‰)
- **å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„ç»„ä»¶** (agent, chain, executor, workflow, multi_agent, langgraph, graph)
- å¤šæ­¥éª¤è¿‡ç¨‹å’Œæ¨ç†æ­¥éª¤çš„å¼€å§‹

> ğŸ’¡ **é‡è¦è¯´æ˜**: 
> - åè®® `d:`ã€`e:` å’Œ `f:` æ˜¯ **LangGraph ä¸“ç”¨çš„**ï¼Œä¸ä¼šå‡ºç°åœ¨åŸºç¡€ LangChain æµä¸­
> - æ‰€æœ‰è‡ªåŠ¨æ”¯æŒçš„åè®®éƒ½å¯ä»¥é€šè¿‡ `AdapterConfig` å•ç‹¬å¯ç”¨æˆ–ç¦ç”¨
> - ç¡®åˆ‡æ ¼å¼å¯èƒ½ä¼šæ ¹æ®åº•å±‚ LangChain/LangGraph äº‹ä»¶ç»“æ„è€Œæœ‰æ‰€ä¸åŒ

### ğŸŸ¡ ä»…æ‰‹åŠ¨æ”¯æŒçš„åè®®

è¿™äº›åè®®éœ€è¦ä½¿ç”¨æˆ‘ä»¬çš„å·¥å‚æ–¹æ³•æ‰‹åŠ¨ç”Ÿæˆï¼š

#### **`g:` (æ¨ç†åè®®)** âš ï¸ **ä»…é™æ‰‹åŠ¨æ”¯æŒ**
**ç”¨é€”**: ä¼ è¾“ AI æ¨ç†è¿‡ç¨‹å’Œæ€ç»´é“¾
**æ ¼å¼**: `g:{"reasoning":"è®©æˆ‘ä¸€æ­¥æ­¥æ€è€ƒè¿™ä¸ªé—®é¢˜...","confidence":0.85}`
**æ‰‹åŠ¨åˆ›å»º**:
```python
from langchain_aisdk_adapter import AISDKFactory

# åˆ›å»ºæ¨ç†åè®®
reasoning_part = AISDKFactory.create_reasoning_part(
    reasoning="è®©æˆ‘åˆ†æç”¨æˆ·çš„è¯·æ±‚...",
    confidence=0.9
)
print(f"g:{reasoning_part.model_dump_json()}")
```
**ä½¿ç”¨åœºæ™¯**: æ€ç»´é“¾æ¨ç†ã€å†³ç­–è§£é‡Šã€ç½®ä¿¡åº¦è¯„åˆ†

#### **`c:` (å·¥å…·è°ƒç”¨å¢é‡åè®®)** âš ï¸ **ä»…é™æ‰‹åŠ¨æ”¯æŒ**
**ç”¨é€”**: åœ¨å·¥å…·è°ƒç”¨æ‰§è¡ŒæœŸé—´æµå¼ä¼ è¾“å¢é‡æ›´æ–°
**æ ¼å¼**: `c:{"toolCallId":"call_123","delta":{"function":{"arguments":"{\"query\":\"hello\"}"}},"index":0}`
**æ‰‹åŠ¨åˆ›å»º**:
```python
from langchain_aisdk_adapter import AISDKFactory

# åˆ›å»ºå·¥å…·è°ƒç”¨å¢é‡
delta_part = AISDKFactory.create_tool_call_delta_part(
    tool_call_id="call_123",
    delta={"function": {"arguments": '{"query":"hello"}'}},
    index=0
)
print(f"c:{delta_part.model_dump_json()}")
```
**ä½¿ç”¨åœºæ™¯**: å®æ—¶å·¥å…·æ‰§è¡Œåé¦ˆã€æµå¼å‡½æ•°è°ƒç”¨

#### **`8:` (æ¶ˆæ¯æ³¨è§£åè®®)** âš ï¸ **ä»…é™æ‰‹åŠ¨æ”¯æŒ**
**ç”¨é€”**: ä¸ºæ¶ˆæ¯æ·»åŠ å…ƒæ•°æ®å’Œæ³¨è§£
**æ ¼å¼**: `8:{"annotations":[{"type":"citation","text":"æ¥æº: ç»´åŸºç™¾ç§‘"}],"metadata":{"confidence":0.95}}`
**æ‰‹åŠ¨åˆ›å»º**:
```python
from langchain_aisdk_adapter import AISDKFactory

# åˆ›å»ºæ¶ˆæ¯æ³¨è§£
annotation_part = AISDKFactory.create_message_annotation_part(
    annotations=[{"type": "citation", "text": "æ¥æº: ç»´åŸºç™¾ç§‘"}],
    metadata={"confidence": 0.95}
)
print(f"8:{annotation_part.model_dump_json()}")
```
**ä½¿ç”¨åœºæ™¯**: æ¥æºå¼•ç”¨ã€ç½®ä¿¡åº¦è¯„åˆ†ã€å†…å®¹å…ƒæ•°æ®

#### **`h:` (æ¥æºåè®®)** âœ… **æ‰‹åŠ¨æ”¯æŒ**
**æ‰‹åŠ¨åˆ›å»º**: ä½¿ç”¨ `create_source_part(url, title=None)` æˆ– `AISDKFactory.source(url, title=None)`
**æ ¼å¼**: `h:{"url":"https://example.com","title":"æ–‡æ¡£æ ‡é¢˜"}`
**ä½¿ç”¨åœºæ™¯**: æ–‡æ¡£å¼•ç”¨ã€å¼•ç”¨è·Ÿè¸ªã€æ¥æºå½’å±

#### **`i:` (åˆ èŠ‚æ¨ç†åè®®)** âœ… **æ‰‹åŠ¨æ”¯æŒ**
**æ‰‹åŠ¨åˆ›å»º**: ä½¿ç”¨ `create_redacted_reasoning_part(data)` æˆ– `AISDKFactory.redacted_reasoning(data)`
**æ ¼å¼**: `i:{"data":"[å·²åˆ èŠ‚] æ¨ç†å†…å®¹"}`
**ä½¿ç”¨åœºæ™¯**: éšç§åˆè§„çš„æ¨ç†è¾“å‡ºã€å†…å®¹è¿‡æ»¤

#### **`j:` (æ¨ç†ç­¾ååè®®)** âœ… **æ‰‹åŠ¨æ”¯æŒ**
**æ‰‹åŠ¨åˆ›å»º**: ä½¿ç”¨ `create_reasoning_signature_part(signature)` æˆ– `AISDKFactory.reasoning_signature(signature)`
**æ ¼å¼**: `j:{"signature":"signature_abc123"}`
**ä½¿ç”¨åœºæ™¯**: æ¨ç†éªŒè¯ã€æ¨¡å‹ç­¾åã€çœŸå®æ€§è·Ÿè¸ª

#### **`k:` (æ–‡ä»¶åè®®)** âœ… **æ‰‹åŠ¨æ”¯æŒ**
**æ‰‹åŠ¨åˆ›å»º**: ä½¿ç”¨ `create_file_part(data, mime_type)` æˆ– `AISDKFactory.file(data, mime_type)`
**æ ¼å¼**: `k:{"data":"base64_encoded_data","mimeType":"image/png"}`
**ä½¿ç”¨åœºæ™¯**: æ–‡ä»¶é™„ä»¶ã€äºŒè¿›åˆ¶æ•°æ®ä¼ è¾“ã€æ–‡æ¡£å…±äº«

### ğŸ”´ å½“å‰ä¸æ”¯æŒçš„åè®®

æˆ‘ä»¬æ­£åœ¨åŠªåŠ›æ”¯æŒè¿™äº›åè®®ï¼Œä½†ç›®å‰è¿˜ä¸å¯ç”¨ï¼š

- **`1:` (å‡½æ•°è°ƒç”¨)**: ä¸ LangChain çš„å·¥å…·ç³»ç»Ÿæ¶æ„ä¸åŒ
- **`4:` (å·¥å…·è°ƒç”¨æµ)**: éœ€è¦å½“å‰ LangChain ç‰ˆæœ¬ä¸­ä¸å¯ç”¨çš„æµå¼å‚æ•°æ”¯æŒ
- **`5:` (å·¥å…·è°ƒç”¨æµéƒ¨åˆ†)**: ä¸ä¸Šè¿°é™åˆ¶ç›¸åŒ
- **`6:` (å·¥å…·è°ƒç”¨æµå¢é‡)**: ä¸ä¸Šè¿°é™åˆ¶ç›¸åŒ
- **`7:` (å·¥å…·è°ƒç”¨æµå®Œæˆ)**: ä¸ä¸Šè¿°é™åˆ¶ç›¸åŒ

## ğŸ› ï¸ æ‰‹åŠ¨åè®®ç”Ÿæˆ

å¯¹äºéœ€è¦æ‰‹åŠ¨å®ç°çš„åè®®ï¼Œæˆ‘ä»¬æä¾›äº†ä¾¿æ·çš„å·¥å‚æ–¹æ³•ï¼š

```python
from langchain_aisdk_adapter.factory import AISDKFactory

# åˆ›å»ºå·¥å‚å®ä¾‹
factory = AISDKFactory()

# ç”Ÿæˆæ¨ç†åè®®
reasoning_part = factory.reasoning(
    content="è®©æˆ‘ä¸€æ­¥æ­¥æ€è€ƒè¿™ä¸ªé—®é¢˜..."
)

# ç”Ÿæˆæ¥æºåè®®
source_part = factory.source(
    url="https://example.com/document",
    title="é‡è¦æ–‡æ¡£"
)

# ç”Ÿæˆåˆ èŠ‚æ¨ç†åè®®
redacted_part = factory.redacted_reasoning(
    data="[å·²åˆ èŠ‚] æ•æ„Ÿæ¨ç†å†…å®¹"
)

# ç”Ÿæˆæ¨ç†ç­¾ååè®®
signature_part = factory.reasoning_signature(
    signature="model_signature_abc123"
)

# ç”Ÿæˆæ–‡ä»¶åè®®
file_part = factory.file(
    data="iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==",
    mime_type="image/png"
)

# ç”Ÿæˆæ¶ˆæ¯æ³¨è§£
annotation_part = factory.annotation(
    message_id="msg_123",
    annotation_type="confidence",
    value={"score": 0.95}
)

# ç”Ÿæˆå·¥å…·è°ƒç”¨å¢é‡ï¼ˆç”¨äºæµå¼å‚æ•°ï¼‰
tool_delta_part = factory.tool_call_delta(
    tool_call_id="call_123",
    name="search",
    args_delta='{"query": "äººå·¥æ™ºèƒ½'  # éƒ¨åˆ† JSON
)
```

### å·¥å‚å®ä¾‹ä½¿ç”¨

ä½¿ç”¨ç®€åŒ–çš„å·¥å‚å®ä¾‹å¿«é€Ÿåˆ›å»ºåè®®ï¼š

```python
from langchain_aisdk_adapter import factory

# åˆ›å»ºå„ç§åè®®éƒ¨åˆ†
text_part = factory.text("æ¥è‡ª LangChain çš„é—®å€™ï¼")
data_part = factory.data({"temperature": 0.7, "max_tokens": 100})
error_part = factory.error("è¿æ¥è¶…æ—¶")
reasoning_part = factory.reasoning("åŸºäºä¸Šä¸‹æ–‡ï¼Œæˆ‘åº”è¯¥...")
source_part = factory.source(
    url="https://docs.langchain.com",
    title="LangChain æ–‡æ¡£"
)

# åœ¨æµå¼å“åº”ä¸­ä½¿ç”¨
async def stream_with_factory():
    yield text_part
    yield reasoning_part
    yield data_part
```

**ä¸ºä»€ä¹ˆéœ€è¦æ‰‹åŠ¨å®ç°ï¼Ÿ**

ç”±äºæŠ€æœ¯é™åˆ¶ï¼Œæˆ‘ä»¬ä¸å¾—ä¸å°†æŸäº›åè®®è®¾ä¸ºæ‰‹åŠ¨ï¼š
- **æ¨ç†å†…å®¹**: ä¸åŒçš„ LLM ä½¿ç”¨ä¸åŒçš„æ¨ç†æ ¼å¼ï¼Œæ— æ³•è‡ªåŠ¨æ ‡å‡†åŒ–
- **å·¥å…·è°ƒç”¨å¢é‡**: LangChain çš„å·¥å…·ç³»ç»Ÿä¸æä¾›æµå¼å‚æ•°ç”Ÿæˆ
- **æ¶ˆæ¯æ³¨è§£**: LangChain ç¼ºä¹æ ‡å‡†åŒ–çš„æ¶ˆæ¯å…ƒæ•°æ®äº‹ä»¶ç³»ç»Ÿ
- **æ¥æºè·Ÿè¸ª**: æ–‡æ¡£æ¥æºä¿¡æ¯éœ€è¦æ˜¾å¼çš„åº”ç”¨çº§å®ç°
- **å†…å®¹è¿‡æ»¤**: åˆ èŠ‚æ¨ç†éœ€è¦è‡ªå®šä¹‰éšç§å’Œå®‰å…¨ç­–ç•¥
- **æ–‡ä»¶å¤„ç†**: äºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†å’Œç¼–ç åœ¨ä¸åŒå®ç°ä¸­å·®å¼‚å¾ˆå¤§

## ğŸŒ Web é›†æˆç¤ºä¾‹

æˆ‘ä»¬ä¸º Web æ¡†æ¶æä¾›äº†å…¨é¢çš„ç¤ºä¾‹ï¼š

### FastAPI é›†æˆ

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from langchain_aisdk_adapter import LangChainAdapter

app = FastAPI()

@app.post("/chat")
async def chat(message: str):
    # æ‚¨çš„ LangChain è®¾ç½®
    stream = llm.astream([HumanMessage(content=message)])
    
    return StreamingResponse(
        LangChainAdapter.to_data_stream_response(stream),
        media_type="text/plain"
    )
```

### å¤šè½®å¯¹è¯

å¤„ç†å¸¦æœ‰æ¶ˆæ¯å†å²çš„å¤šè½®å¯¹è¯ï¼š

```python
from langchain_core.messages import HumanMessage, AIMessage
from langchain_aisdk_adapter import LangChainAdapter

async def multi_turn_chat():
    conversation_history = []
    
    # ç¬¬ä¸€è½®
    user_input = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
    conversation_history.append(HumanMessage(content=user_input))
    
    response_content = ""
    stream = llm.astream(conversation_history)
    ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)
    
    async for chunk in ai_sdk_stream:
        if chunk.startswith('0:'):
            # ä»åè®®ä¸­æå–æ–‡æœ¬å†…å®¹
            text_content = chunk[2:].strip('"')
            response_content += text_content
        yield chunk
    
    conversation_history.append(AIMessage(content=response_content))
    
    # ç¬¬äºŒè½®
    user_input = "èƒ½ç»™æˆ‘ä¸€ä¸ªä¾‹å­å—ï¼Ÿ"
    conversation_history.append(HumanMessage(content=user_input))
    
    stream = llm.astream(conversation_history)
    ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)
    
    async for chunk in ai_sdk_stream:
        yield chunk
```

æœ‰å…³åŒ…æ‹¬ä»£ç†é›†æˆã€å·¥å…·ä½¿ç”¨å’Œé”™è¯¯å¤„ç†çš„å®Œæ•´ç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹ `web/` ç›®å½•ã€‚

## ğŸ§ª ä½¿ç”¨ç¤ºä¾‹

ä»¥ä¸‹æ˜¯å±•ç¤ºé€‚é…å™¨ä¸åŒä½¿ç”¨æ–¹å¼çš„å…¨é¢ç¤ºä¾‹ï¼š

### åŸºç¡€ LangChain æµå¼å¤„ç†

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_aisdk_adapter import LangChainAdapter

# ç®€å•æµå¼ç¤ºä¾‹
llm = ChatOpenAI(model="gpt-3.5-turbo", streaming=True)
stream = llm.astream([HumanMessage(content="ç»™æˆ‘è®²ä¸ªç¬‘è¯")])

# è½¬æ¢ä¸º AI SDK æ ¼å¼
ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)

# å¤„ç†æµ
async for chunk in ai_sdk_stream:
    print(chunk, end="", flush=True)
    # è¾“å‡º: 0:"ä¸ºä»€ä¹ˆé¸¡è¦è¿‡é©¬è·¯ï¼Ÿ"
    #      0:" å› ä¸ºå®ƒæƒ³åˆ°å¯¹é¢å»ï¼"
```

### LangChain ä¸å·¥å…·

```python
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate
from langchain_aisdk_adapter import LangChainAdapter

# å®šä¹‰å·¥å…·
@tool
def get_weather(city: str) -> str:
    """è·å–åŸå¸‚çš„å¤©æ°”ä¿¡æ¯ã€‚"""
    return f"{city}çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œ25Â°C"

# åˆ›å»ºä»£ç†
llm = ChatOpenAI(model="gpt-3.5-turbo", streaming=True)
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}")
])

agent = create_openai_functions_agent(llm, [get_weather], prompt)
agent_executor = AgentExecutor(agent=agent, tools=[get_weather])

# å¸¦å·¥å…·çš„æµå¼å¤„ç†
stream = agent_executor.astream({"input": "å·´é»çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"})
ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)

async for chunk in ai_sdk_stream:
    print(chunk)
    # è¾“å‡ºåŒ…æ‹¬:
    # 9:{"toolCallId":"call_123","toolName":"get_weather","args":{"city":"å·´é»"}}
    # a:{"toolCallId":"call_123","result":"å·´é»çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œ25Â°C"}
    # 0:"å·´é»çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œ25Â°C"
```

### LangGraph å·¥ä½œæµï¼ˆåŒ…å«æ­¥éª¤åè®®ï¼‰

```python
from langgraph import StateGraph
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain_aisdk_adapter import LangChainAdapter
from typing import TypedDict, List

class State(TypedDict):
    messages: List[HumanMessage | AIMessage]

def chat_node(state: State):
    llm = ChatOpenAI(model="gpt-3.5-turbo", streaming=True)
    response = llm.invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

# åˆ›å»ºå·¥ä½œæµ
workflow = StateGraph(State)
workflow.add_node("chat", chat_node)
workflow.set_entry_point("chat")
workflow.set_finish_point("chat")

app = workflow.compile()

# æµå¼å¤„ç† LangGraph å·¥ä½œæµ
stream = app.astream({"messages": [HumanMessage(content="ä½ å¥½ï¼")]})
ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)

async for chunk in ai_sdk_stream:
    print(chunk)
    # è¾“å‡ºåŒ…æ‹¬ LangGraph ç‰¹å®šåè®®:
    # f:{"stepId":"step_123","stepType":"node_execution"}
    # 0:"ä½ å¥½ï¼æˆ‘ä»Šå¤©èƒ½ä¸ºæ‚¨åšäº›ä»€ä¹ˆï¼Ÿ"
    # e:{"stepId":"step_123","finishReason":"completed"}
    # d:{"finishReason":"stop","usage":{"promptTokens":10,"completionTokens":15}}
```

### è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹

```python
from langchain_aisdk_adapter import LangChainAdapter, AdapterConfig

# ä»…æ–‡æœ¬è¾“å‡º
config = AdapterConfig(
    enable_text=True,
    enable_data=False,
    enable_tool_calls=False,
    enable_steps=False
)

# ä»…å·¥å…·äº¤äº’
config = AdapterConfig.tools_only()

# é™¤æ­¥éª¤å¤–çš„æ‰€æœ‰åŠŸèƒ½ï¼ˆé€‚ç”¨äºåŸºç¡€ LangChainï¼‰
config = AdapterConfig(
    enable_text=True,
    enable_data=True,
    enable_tool_calls=True,
    enable_tool_results=True,
    enable_steps=False  # ç¦ç”¨ LangGraph ç‰¹å®šåè®®
)

stream = LangChainAdapter.to_data_stream_response(your_stream, config=config)
```

### å¤šç”¨æˆ·åº”ç”¨çš„çº¿ç¨‹å®‰å…¨é…ç½®

```python
from langchain_aisdk_adapter import ThreadSafeAdapterConfig
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

# ä¸º FastAPI åˆ›å»ºçº¿ç¨‹å®‰å…¨é…ç½®
safe_config = ThreadSafeAdapterConfig()

app = FastAPI()

@app.post("/chat")
async def chat(message: str):
    """æ¯ä¸ªè¯·æ±‚éƒ½æœ‰éš”ç¦»çš„åè®®çŠ¶æ€"""
    stream = llm.astream([HumanMessage(content=message)])
    
    # çº¿ç¨‹å®‰å…¨ï¼šæ¯ä¸ªè¯·æ±‚éƒ½æœ‰éš”ç¦»çš„é…ç½®
    return StreamingResponse(
        LangChainAdapter.to_data_stream_response(stream, config=safe_config),
        media_type="text/plain"
    )

@app.post("/chat-minimal")
async def chat_minimal(message: str):
    """ä»…ä¸ºæ­¤è¯·æ±‚ä¸´æ—¶ç¦ç”¨æŸäº›åè®®"""
    stream = llm.astream([HumanMessage(content=message)])
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸´æ—¶ä¿®æ”¹åè®®
    with safe_config.pause_protocols(['2', '9', 'a']):  # ç¦ç”¨æ•°æ®å’Œå·¥å…·
        return StreamingResponse(
            LangChainAdapter.to_data_stream_response(stream, config=safe_config),
            media_type="text/plain"
        )
    # ä¸Šä¸‹æ–‡ç»“æŸååè®®è‡ªåŠ¨æ¢å¤

@app.post("/chat-selective")
async def chat_selective(message: str):
    """ä»…ä¸ºæ­¤è¯·æ±‚å¯ç”¨ç‰¹å®šåè®®"""
    stream = llm.astream([HumanMessage(content=message)])
    
    # ä»…å¯ç”¨æ–‡æœ¬å’Œæ•°æ®åè®®
    with safe_config.protocols(['0', '2']):
        return StreamingResponse(
            LangChainAdapter.to_data_stream_response(stream, config=safe_config),
            media_type="text/plain"
        )
```

### åè®®ä¸Šä¸‹æ–‡ç®¡ç†

```python
from langchain_aisdk_adapter import AdapterConfig, ThreadSafeAdapterConfig

# å¸¦ä¸Šä¸‹æ–‡ç®¡ç†çš„å¸¸è§„é…ç½®
config = AdapterConfig()

# ä¸´æ—¶ç¦ç”¨ç‰¹å®šåè®®
with config.pause_protocols(['0', '2']):  # æš‚åœæ–‡æœ¬å’Œæ•°æ®
    # åªä¼šç”Ÿæˆå·¥å…·è°ƒç”¨å’Œç»“æœ
    stream = LangChainAdapter.to_data_stream_response(some_stream, config=config)
    async for chunk in stream:
        print(chunk)  # æ²¡æœ‰æ–‡æœ¬æˆ–æ•°æ®åè®®
# åè®®è‡ªåŠ¨æ¢å¤

# ä»…å¯ç”¨ç‰¹å®šåè®®
with config.protocols(['0', '9', 'a']):  # ä»…æ–‡æœ¬ã€å·¥å…·è°ƒç”¨å’Œç»“æœ
    stream = LangChainAdapter.to_data_stream_response(some_stream, config=config)
    async for chunk in stream:
        print(chunk)  # ä»…æŒ‡å®šçš„åè®®

# å¹¶å‘åº”ç”¨çš„çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬
safe_config = ThreadSafeAdapterConfig()

# æ¯ä¸ªä¸Šä¸‹æ–‡éƒ½æŒ‰è¯·æ±‚/çº¿ç¨‹éš”ç¦»
with safe_config.protocols(['0']):  # ä»…æ–‡æœ¬
    # è¿™ä¸ä¼šå½±å“å…¶ä»–å¹¶å‘è¯·æ±‚
    stream = LangChainAdapter.to_data_stream_response(stream1, config=safe_config)

# æ”¯æŒåµŒå¥—ä¸Šä¸‹æ–‡
with safe_config.pause_protocols(['2']):
    with safe_config.protocols(['0', '9']):
        # ä»…æ–‡æœ¬å’Œå·¥å…·è°ƒç”¨ï¼Œæ•°æ®è¢«æš‚åœ
        stream = LangChainAdapter.to_data_stream_response(stream2, config=safe_config)
```

### é”™è¯¯å¤„ç†

```python
from langchain_aisdk_adapter import LangChainAdapter
import asyncio

async def safe_streaming():
    try:
        stream = llm.astream([HumanMessage(content="ä½ å¥½")])
        ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)
        
        async for chunk in ai_sdk_stream:
            print(chunk, end="", flush=True)
            
    except Exception as e:
        print(f"æµå¼å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        # é€‚å½“å¤„ç†é”™è¯¯

asyncio.run(safe_streaming())
```

### ä¸å›è°ƒé›†æˆ

```python
from langchain_core.callbacks import AsyncCallbackHandler
from langchain_aisdk_adapter import LangChainAdapter

class CustomCallback(AsyncCallbackHandler):
    async def on_llm_start(self, serialized, prompts, **kwargs):
        print("LLM å¼€å§‹")
    
    async def on_llm_end(self, response, **kwargs):
        print("LLM ç»“æŸ")

# ä½¿ç”¨å›è°ƒ
llm = ChatOpenAI(model="gpt-3.5-turbo", streaming=True, callbacks=[CustomCallback()])
stream = llm.astream([HumanMessage(content="ä½ å¥½")])
ai_sdk_stream = LangChainAdapter.to_data_stream_response(stream)

# é€‚é…å™¨å°†æ•è·å›è°ƒäº‹ä»¶ä½œä¸ºæ•°æ®åè®®
async for chunk in ai_sdk_stream:
    print(chunk)
    # å¯èƒ½åŒ…æ‹¬: 2:[{"event":"llm_start","timestamp":"..."}]
```

## ğŸ§ª æµ‹è¯•

æˆ‘ä»¬è®¤çœŸå¯¹å¾…æµ‹è¯•å¹¶ä¿æŒé«˜è¦†ç›–ç‡ï¼š

```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install langchain-aisdk-adapter[dev]

# è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•
pytest tests/ -v --cov=src --cov-report=term-missing

# å½“å‰è¦†ç›–ç‡: 98%
```

## ğŸ“š API å‚è€ƒ

### LangChainAdapter

ä¸»è¦é€‚é…å™¨ç±»ï¼š

```python
class LangChainAdapter:
    @staticmethod
    async def to_data_stream_response(
        stream: AsyncIterator,
        config: Optional[AdapterConfig] = None
    ) -> AsyncIterator[str]:
        """å°† LangChain æµè½¬æ¢ä¸º AI SDK æ ¼å¼"""
```

### AdapterConfig

ç”¨äºæ§åˆ¶åè®®ç”Ÿæˆçš„é…ç½®ç±»ï¼š

```python
class AdapterConfig:
    enable_text: bool = True
    enable_data: bool = True
    enable_tool_calls: bool = True
    enable_tool_results: bool = True
    enable_steps: bool = True
    enable_reasoning: bool = False  # ä»…æ‰‹åŠ¨
    enable_annotations: bool = False  # ä»…æ‰‹åŠ¨
    enable_files: bool = False  # ä»…æ‰‹åŠ¨
    
    @classmethod
    def minimal(cls) -> "AdapterConfig": ...
    
    @classmethod
    def tools_only(cls) -> "AdapterConfig": ...
    
    @classmethod
    def comprehensive(cls) -> "AdapterConfig": ...
    
    @contextmanager
    def pause_protocols(self, protocol_types: List[str]):
        """ä¸´æ—¶ç¦ç”¨ç‰¹å®šåè®®ç±»å‹"""
    
    @contextmanager
    def protocols(self, protocol_types: List[str]):
        """ä»…å¯ç”¨ç‰¹å®šåè®®ç±»å‹"""
```

### ThreadSafeAdapterConfig

å¤šç”¨æˆ·åº”ç”¨çš„çº¿ç¨‹å®‰å…¨é…ç½®åŒ…è£…å™¨ï¼š

```python
class ThreadSafeAdapterConfig:
    def __init__(self, base_config: Optional[AdapterConfig] = None):
        """ä½¿ç”¨å¯é€‰çš„åŸºç¡€é…ç½®åˆå§‹åŒ–"""
    
    def is_protocol_enabled(self, protocol_type: str) -> bool:
        """æ£€æŸ¥åè®®æ˜¯å¦å¯ç”¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    
    @contextmanager
    def pause_protocols(self, protocol_types: List[str]):
        """çº¿ç¨‹å®‰å…¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä¸´æ—¶ç¦ç”¨åè®®"""
    
    @contextmanager
    def protocols(self, protocol_types: List[str]):
        """çº¿ç¨‹å®‰å…¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä»…å¯ç”¨ç‰¹å®šåè®®"""
```

**ä¸»è¦ç‰¹æ€§ï¼š**
- **çº¿ç¨‹éš”ç¦»**: æ¯ä¸ªè¯·æ±‚/çº¿ç¨‹éƒ½æœ‰éš”ç¦»çš„åè®®çŠ¶æ€
- **ä¸Šä¸‹æ–‡ç®¡ç†**: æ”¯æŒåµŒå¥—ä¸Šä¸‹æ–‡ç®¡ç†å™¨
- **FastAPI å°±ç»ª**: å®Œç¾é€‚ç”¨äºå¤šç”¨æˆ· Web åº”ç”¨
- **åŸºç¡€é…ç½®æ”¯æŒ**: å¯ä»¥åŒ…è£…ç°æœ‰çš„ AdapterConfig å®ä¾‹

### AISDKFactory

æ‰‹åŠ¨åè®®åˆ›å»ºçš„å·¥å‚ç±»ï¼š

```python
class AISDKFactory:
    @staticmethod
    def create_reasoning_part(
        reasoning: str,
        confidence: Optional[float] = None
    ) -> ReasoningPartContent:
        """åˆ›å»ºæ¨ç†åè®®éƒ¨åˆ†"""
    
    @staticmethod
    def create_tool_call_delta_part(
        tool_call_id: str,
        delta: Dict[str, Any],
        index: int = 0
    ) -> ToolCallDeltaPartContent:
        """åˆ›å»ºå·¥å…·è°ƒç”¨å¢é‡åè®®éƒ¨åˆ†"""
    
    @staticmethod
    def create_message_annotation_part(
        annotations: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None
    ) -> MessageAnnotationPartContent:
        """åˆ›å»ºæ¶ˆæ¯æ³¨é‡Šåè®®éƒ¨åˆ†"""
    
    @staticmethod
    def create_source_part(
        source_id: str,
        source_type: str,
        content: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> SourcePartContent:
        """åˆ›å»ºæ¥æºåè®®éƒ¨åˆ†"""
    
    @staticmethod
    def create_file_part(
        file_id: str,
        file_name: str,
        file_type: str,
        content: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> FilePartContent:
         """åˆ›å»ºæ–‡ä»¶åè®®éƒ¨åˆ†"""

### å·¥å‚å‡½æ•°ï¼ˆå‘åå…¼å®¹ï¼‰

ç”¨äºåˆ›å»ºåè®®éƒ¨åˆ†çš„ä¾¿æ·å‡½æ•°ï¼š

```python
# åŸºç¡€åè®®åˆ›å»º
create_text_part(text: str) -> AISDKPartEmitter
create_data_part(data: Any) -> AISDKPartEmitter
create_error_part(error: str) -> AISDKPartEmitter

# å·¥å…·ç›¸å…³åè®®
create_tool_call_part(tool_call_id: str, tool_name: str, args: Dict) -> AISDKPartEmitter
create_tool_result_part(tool_call_id: str, result: str) -> AISDKPartEmitter
create_tool_call_streaming_start_part(tool_call_id: str, tool_name: str) -> AISDKPartEmitter

# æ­¥éª¤åè®®
create_start_step_part(message_id: str) -> AISDKPartEmitter
create_finish_step_part(finish_reason: str, **kwargs) -> AISDKPartEmitter
create_finish_message_part(finish_reason: str, **kwargs) -> AISDKPartEmitter

# é«˜çº§åè®®
create_redacted_reasoning_part(reasoning: str) -> AISDKPartEmitter
create_reasoning_signature_part(signature: str) -> AISDKPartEmitter

# é€šç”¨å·¥å‚
create_ai_sdk_part(protocol_type: str, content: Any) -> AISDKPartEmitter
```

### å·¥å‚å®ä¾‹

å…·æœ‰ç®€åŒ–æ–¹æ³•çš„ä¾¿æ·å·¥å‚å®ä¾‹ï¼š

```python
from langchain_aisdk_adapter import factory

# ç®€åŒ–çš„å·¥å‚æ–¹æ³•
text_part = factory.text("ä½ å¥½ä¸–ç•Œ")
data_part = factory.data(["é”®", "å€¼"])
error_part = factory.error("å‡ºç°é”™è¯¯")
reasoning_part = factory.reasoning("è®©æˆ‘æƒ³æƒ³...")
source_part = factory.source(url="https://example.com", title="ç¤ºä¾‹")
```

### é…ç½®å®ä¾‹

å¸¸è§ç”¨ä¾‹çš„é¢„é…ç½®å®ä¾‹ï¼š

```python
from langchain_aisdk_adapter import default_config, safe_config

# é»˜è®¤é…ç½®å®ä¾‹
default_config: AdapterConfig

# çº¿ç¨‹å®‰å…¨é…ç½®å®ä¾‹
safe_config: ThreadSafeAdapterConfig
```

## ğŸ¤ è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿è´¡çŒ®ï¼è¿™ä¸ªé¡¹ç›®ä»å¤„äº alpha é˜¶æ®µï¼Œæ‰€ä»¥æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ï¼š

1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. è¿›è¡Œæ›´æ”¹å¹¶æ·»åŠ æµ‹è¯•
4. ç¡®ä¿æµ‹è¯•é€šè¿‡ (`pytest tests/`)
5. æäº¤ Pull Request

è¯·éšæ—¶ï¼š
- æŠ¥å‘Šé”™è¯¯å’Œé—®é¢˜
- å»ºè®®æ–°åŠŸèƒ½
- æ”¹è¿›æ–‡æ¡£
- æ·»åŠ æ›´å¤šç¤ºä¾‹
- æé«˜æµ‹è¯•è¦†ç›–ç‡

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache License 2.0 è®¸å¯è¯ - è¯¦æƒ…è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

æˆ‘ä»¬æ„Ÿè°¢ï¼š
- LangChain å›¢é˜Ÿæä¾›çš„ä¼˜ç§€æ¡†æ¶
- AI SDK ç¤¾åŒºæä¾›çš„æµåè®®è§„èŒƒ
- æ‰€æœ‰å¸®åŠ©æ”¹è¿›è¿™ä¸ªé¡¹ç›®çš„è´¡çŒ®è€…å’Œç”¨æˆ·

## ğŸ“ æ”¯æŒ

å¦‚æœæ‚¨é‡åˆ°ä»»ä½•é—®é¢˜æˆ–æœ‰ç–‘é—®ï¼š

- ğŸ“‹ [æäº¤é—®é¢˜](https://github.com/lointain/langchain_aisdk_adapter/issues)
- ğŸ“– [æŸ¥çœ‹æ–‡æ¡£](https://github.com/lointain/langchain_aisdk_adapter#readme)
- ğŸ’¬ [å¼€å§‹è®¨è®º](https://github.com/lointain/langchain_aisdk_adapter/discussions)

æˆ‘ä»¬æ„Ÿè°¢æ‚¨åœ¨æˆ‘ä»¬ç»§ç»­æ”¹è¿›è¿™ä¸ª alpha ç‰ˆæœ¬æ—¶çš„è€å¿ƒï¼

---

*ä¸º LangChain å’Œ AI SDK ç¤¾åŒºç”¨ â¤ï¸ åˆ¶ä½œ*