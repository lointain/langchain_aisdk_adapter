# LangChain AI SDK é€‚é…å™¨

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI version](https://badge.fury.io/py/langchain-aisdk-adapter.svg)](https://badge.fury.io/py/langchain-aisdk-adapter)

ä¸€ä¸ªå°è¯•å°† LangChain æµå¼è¾“å‡ºè½¬æ¢ä¸º AI SDK å…¼å®¹æ•°æ®æµçš„ Python é€‚é…å™¨ã€‚è¯¥åº“è‡´åŠ›äºåœ¨ LangChain å’Œ AI SDK åè®®ä¹‹é—´å»ºç«‹æ¡¥æ¢ï¼Œä½†å¯èƒ½æ— æ³•è¦†ç›–æ‰€æœ‰è¾¹ç¼˜æƒ…å†µå’Œä½¿ç”¨åœºæ™¯ã€‚

## ç‰¹æ€§

- **ğŸ”„ åè®®æ”¯æŒ**ï¼šåŸºæœ¬æ”¯æŒ AI SDK v4 å’Œ v5 åè®®ï¼ˆå¯èƒ½æ— æ³•è¦†ç›–æ‰€æœ‰åè®®ç»†èŠ‚ï¼‰
- **ğŸ“¡ æµå¼è½¬æ¢**ï¼šå°è¯•å°† LangChain `astream_events()` è½¬æ¢ä¸º AI SDK æ•°æ®æµ
- **ğŸ› ï¸ å·¥å…·é›†æˆ**ï¼šæœ‰é™æ”¯æŒå·¥å…·è°ƒç”¨å’Œå·¥å…·è¾“å‡º
- **ğŸ“ ä¸°å¯Œå†…å®¹**ï¼šå¤„ç†å¸¸è§å†…å®¹ç±»å‹å¦‚æ–‡æœ¬ã€æ¨ç†ã€æ–‡ä»¶å’Œæ¥æºï¼ˆæŸäº›è¾¹ç¼˜æƒ…å†µå¯èƒ½æœªè¦†ç›–ï¼‰
- **âš¡ FastAPI é›†æˆ**ï¼šåŸºæœ¬çš„ FastAPI `StreamingResponse` é›†æˆ
- **ğŸ¯ æ‰‹åŠ¨æ§åˆ¶**ï¼šæä¾›æ‰‹åŠ¨äº‹ä»¶å‘å°„åŠŸèƒ½
- **ğŸ”§ çµæ´»é…ç½®**ï¼šå¯é…ç½®åè®®ç‰ˆæœ¬å’Œè¾“å‡ºæ ¼å¼
- **ğŸ“Š ä½¿ç”¨è·Ÿè¸ª**ï¼šåŸºæœ¬çš„ä»¤ç‰Œä½¿ç”¨å’Œæ€§èƒ½ç›‘æ§
- **ğŸŒŠ å¹³æ»‘æµå¼ä¼ è¾“**ï¼šå†…ç½® `smooth_stream` åŠŸèƒ½ï¼Œæä¾›å¢å¼ºçš„æ–‡æœ¬è¾“å‡ºå¹³æ»‘å¤„ç†
- **ğŸ”— æ‰©å±•å›è°ƒç³»ç»Ÿ**ï¼šå…¨é¢çš„å›è°ƒç³»ç»Ÿï¼Œæ”¯æŒ `onChunk`ã€`onError`ã€`onStepFinish`ã€`onFinish` å’Œ `onAbort`
- **ğŸ§ª å®éªŒæ€§åŠŸèƒ½**ï¼šæ”¯æŒ `experimental_transform` å’Œ `experimental_generateMessageId`

## å·²çŸ¥é™åˆ¶

- **åè®®å…¼å®¹æ€§**ï¼šè™½ç„¶æˆ‘ä»¬åŠªåŠ›ä¿æŒå…¼å®¹æ€§ï¼Œä½†æŸäº› AI SDK åŠŸèƒ½å¯èƒ½æ— æ³•å®Œå…¨æ”¯æŒ
- **é”™è¯¯å¤„ç†**ï¼šå¤æ‚æµå¼åœºæ™¯ä¸­çš„é”™è¯¯æƒ…å†µå¯èƒ½éœ€è¦é¢å¤–å¤„ç†
- **å·¥å…·å¤æ‚æ€§**ï¼šé«˜çº§å·¥å…·è°ƒç”¨æ¨¡å¼å¯èƒ½éœ€è¦è‡ªå®šä¹‰å®ç°
- **æµ‹è¯•è¦†ç›–**ï¼šæŸäº›è¾¹ç¼˜æƒ…å†µå’Œå¤æ‚åœºæ™¯å¯èƒ½æœªç»å……åˆ†æµ‹è¯•

## å®‰è£…

```bash
pip install -i https://test.pypi.org/simple/ langchain-aisdk-adapter
```

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ç”¨æ³•

```python
from langchain_aisdk_adapter import LangChainAdapter
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ–æ‚¨çš„ LangChain æ¨¡å‹
llm = ChatOpenAI(model="gpt-4")
messages = [HumanMessage(content="ä½ å¥½ï¼Œä¸–ç•Œï¼")]

# è½¬æ¢ä¸º AI SDK æ•°æ®æµ
stream = llm.astream_events(messages, version="v2")
data_stream = LangChainAdapter.to_data_stream(stream)

# éå†æµ
async for chunk in data_stream:
    print(chunk)
```

### FastAPI é›†æˆ

```python
from fastapi import FastAPI
from langchain_aisdk_adapter import LangChainAdapter
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

app = FastAPI()
llm = ChatOpenAI(model="gpt-4")

@app.post("/api/chat")
async def chat(request: dict):
    messages = [HumanMessage(content=request["message"])]
    stream = llm.astream_events(messages, version="v2")
    
    # è¿”å› FastAPI StreamingResponse
    return LangChainAdapter.to_data_stream_response(
        stream,
        options={"protocol_version": "v5"}  # ä½¿ç”¨ AI SDK v5
    )
```

### åŸºäºä¸Šä¸‹æ–‡çš„äº‹ä»¶å‘å°„

```python
from langchain_aisdk_adapter import LangChainAdapter, DataStreamContext

# åˆ›å»ºå…·æœ‰è‡ªåŠ¨ä¸Šä¸‹æ–‡ç®¡ç†çš„æ•°æ®æµ
stream = llm.astream_events(messages, version="v2")
data_stream = LangChainAdapter.to_data_stream(
    stream, 
    options={"auto_context": True}
)

# ä½¿ç”¨ä¸Šä¸‹æ–‡å‘å‡ºè‡ªå®šä¹‰äº‹ä»¶
context = DataStreamContext.get_current_stream()
if context:
    await context.emit_text_delta("è‡ªå®šä¹‰æ–‡æœ¬")
    await context.emit_source_url("https://example.com", "ç¤ºä¾‹")
    await context.emit_data({"key": "value"})
```

## æ ¸å¿ƒç»„ä»¶

### LangChainAdapter

æä¾›ä¸‰ä¸ªæ ¸å¿ƒæ–¹æ³•çš„ä¸»é€‚é…å™¨ç±»ï¼š

#### `to_data_stream_response()`
å°† LangChain æµè½¬æ¢ä¸º FastAPI `StreamingResponse`ï¼š

```python
response = LangChainAdapter.to_data_stream_response(
    stream=langchain_stream,
    options={
        "protocol_version": "v5",  # "v4" æˆ– "v5"
        "output_format": "protocol",  # "chunks" æˆ– "protocol"
        "auto_events": True,
        "auto_close": True
    }
)
```

#### `to_data_stream()`
å°† LangChain æµè½¬æ¢ä¸º `DataStreamWithEmitters`ï¼š

```python
data_stream = LangChainAdapter.to_data_stream(
    stream=langchain_stream,
    message_id="custom-id",
    options={"protocol_version": "v4"}
)
```

#### `merge_into_data_stream()`
å°† LangChain æµåˆå¹¶åˆ°ç°æœ‰æ•°æ®æµå†™å…¥å™¨ä¸­ï¼š

```python
from langchain_aisdk_adapter import DataStreamWriter

writer = DataStreamWriter()
await LangChainAdapter.merge_into_data_stream(
    stream=langchain_stream,
    data_stream_writer=writer
)
```

### åè®®æ”¯æŒ

#### AI SDK v4 åè®®
- æ–‡æœ¬æ ¼å¼ï¼š`text/plain; charset=utf-8`
- å¤´éƒ¨ï¼š`x-vercel-ai-data-stream: v1`
- æ ¼å¼ï¼š`<type>:<data>\n`

#### AI SDK v5 åè®®
- æ–‡æœ¬æ ¼å¼ï¼š`text/event-stream`
- å¤´éƒ¨ï¼š`x-vercel-ai-ui-message-stream: v1`
- æ ¼å¼ï¼šæœåŠ¡å™¨å‘é€äº‹ä»¶ (SSE)

### é…ç½®é€‰é¡¹

```python
options = {
    "protocol_version": "v5",      # "v4" æˆ– "v5"
    "output_format": "protocol",   # "chunks" æˆ– "protocol"
    "auto_events": True,           # è‡ªåŠ¨å‘å‡ºå¼€å§‹/ç»“æŸäº‹ä»¶
    "auto_close": True,            # è‡ªåŠ¨å…³é—­æµ
    "emit_start": True,            # å‘å‡ºå¼€å§‹äº‹ä»¶
    "emit_finish": True            # å‘å‡ºç»“æŸäº‹ä»¶
}
```

## é«˜çº§åŠŸèƒ½

### å¹³æ»‘æµå¼ä¼ è¾“

`smooth_stream` æ–¹æ³•æä¾›å¢å¼ºçš„æ–‡æœ¬è¾“å‡ºå¹³æ»‘å¤„ç†ï¼Œæ”¯æŒå¯é…ç½®çš„åˆ†å—ç­–ç•¥å’Œå»¶è¿Ÿï¼š

```python
from langchain_aisdk_adapter import LangChainAdapter
import re

# åŸºäºå•è¯çš„åˆ†å—ï¼Œå¸¦å»¶è¿Ÿ
smooth_transform = LangChainAdapter.smooth_stream(
    delayInMs=50,
    chunking='word'
)

# åŸºäºè¡Œçš„åˆ†å—
smooth_transform = LangChainAdapter.smooth_stream(
    delayInMs=100,
    chunking='line'
)

# è‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼åˆ†å—ï¼ˆä¾‹å¦‚ï¼Œç”¨äºä¸­æ–‡æ–‡æœ¬ï¼‰
smooth_transform = LangChainAdapter.smooth_stream(
    delayInMs=30,
    chunking=re.compile(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\S')
)

# è‡ªå®šä¹‰åˆ†å—å‡½æ•°
def custom_chunker(text: str) -> list[str]:
    return text.split('ï¼Œ')

smooth_transform = LangChainAdapter.smooth_stream(
    delayInMs=75,
    chunking=custom_chunker
)

# ä¸ experimental_transform ä¸€èµ·ä½¿ç”¨
data_stream = LangChainAdapter.to_data_stream(
    stream=langchain_stream,
    options={
        "experimental_transform": smooth_transform
    }
)
```

### æ‰©å±•å›è°ƒç³»ç»Ÿ

æ”¯æŒ AI SDK æµå¼äº‹ä»¶çš„å…¨é¢å›è°ƒç³»ç»Ÿï¼š

```python
from langchain_aisdk_adapter import BaseAICallbackHandler

class ExtendedCallback(BaseAICallbackHandler):
    async def on_chunk(self, chunk, **kwargs):
        """æ¯ä¸ªæµå—æ—¶è°ƒç”¨"""
        print(f"æ”¶åˆ°å—ï¼š{chunk}")
    
    async def on_step_finish(self, step_result, **kwargs):
        """æ­¥éª¤å®Œæˆæ—¶è°ƒç”¨"""
        print(f"æ­¥éª¤å®Œæˆï¼š{step_result}")
    
    async def on_finish(self, message, options, **kwargs):
        """æµå¼ä¼ è¾“å®Œæˆæ—¶è°ƒç”¨"""
        print(f"æµå®Œæˆï¼š{message}")
    
    async def on_error(self, error, **kwargs):
        """å‘ç”Ÿé”™è¯¯æ—¶è°ƒç”¨"""
        print(f"æµé”™è¯¯ï¼š{error}")
    
    async def on_abort(self, **kwargs):
        """æµå¼ä¼ è¾“ä¸­æ­¢æ—¶è°ƒç”¨"""
        print("æµå·²ä¸­æ­¢")

callbacks = ExtendedCallback()
data_stream = LangChainAdapter.to_data_stream(
    stream=langchain_stream,
    callbacks=callbacks
)
```

### å®éªŒæ€§åŠŸèƒ½

```python
# è‡ªå®šä¹‰æ¶ˆæ¯ ID ç”Ÿæˆ
def generate_custom_id():
    return f"custom-{uuid.uuid4()}"

# ä½¿ç”¨å®éªŒæ€§åŠŸèƒ½
data_stream = LangChainAdapter.to_data_stream(
    stream=langchain_stream,
    options={
        "experimental_transform": LangChainAdapter.smooth_stream(delayInMs=50),
        "experimental_generateMessageId": generate_custom_id
    }
)
```

### è‡ªå®šä¹‰å›è°ƒï¼ˆä¼ ç»Ÿï¼‰

```python
from langchain_aisdk_adapter import BaseAICallbackHandler

class CustomCallback(BaseAICallbackHandler):
    async def on_text_delta(self, delta: str, **kwargs):
        print(f"æ–‡æœ¬å¢é‡ï¼š{delta}")
    
    async def on_tool_call_start(self, tool_name: str, **kwargs):
        print(f"å·¥å…·è°ƒç”¨å¼€å§‹ï¼š{tool_name}")

callbacks = CustomCallback()
data_stream = LangChainAdapter.to_data_stream(
    stream=langchain_stream,
    callbacks=callbacks
)
```

### ä¸Šä¸‹æ–‡ç®¡ç†

```python
# ä½¿ç”¨ DataStreamContext è¿›è¡Œäº‹ä»¶å‘å°„
from langchain_aisdk_adapter import DataStreamContext

# åœ¨å›è°ƒæˆ–å¤„ç†å™¨ä¸­
context = DataStreamContext.get_current_stream()
if context:
    # å‘å‡ºå„ç§å—ç±»å‹
    await context.emit_text_start("text-1")
    await context.emit_text_delta("ä½ å¥½", "text-1")
    await context.emit_text_end("ä½ å¥½ä¸–ç•Œ", "text-1")
    
    # å‘å‡ºå·¥å…·è°ƒç”¨
    await context.emit_tool_input_start("tool-1", "search")
    await context.emit_tool_input_available("tool-1", "search", {"query": "AI"})
    await context.emit_tool_output_available("tool-1", "æ‰¾åˆ°ç»“æœ")
```

### é”™è¯¯å¤„ç†

```python
try:
    data_stream = LangChainAdapter.to_data_stream(stream)
    async for chunk in data_stream:
        if chunk.get("type") == "error":
            print(f"é”™è¯¯ï¼š{chunk.get('errorText')}")
except Exception as e:
    print(f"æµé”™è¯¯ï¼š{e}")
```

## æ”¯æŒçš„å—ç±»å‹

| å—ç±»å‹ | AI SDK v4 | AI SDK v5 | æè¿° | å¤‡æ³¨ |
|--------|-----------|-----------|------|------|
| `text-start` | âœ… | âœ… | æ–‡æœ¬ç”Ÿæˆå¼€å§‹ | åŸºæœ¬æ”¯æŒ |
| `text-delta` | âœ… | âœ… | æ–‡æœ¬å†…å®¹å¢é‡ | æµ‹è¯•å……åˆ† |
| `text-end` | âœ… | âœ… | æ–‡æœ¬ç”Ÿæˆç»“æŸ | åŸºæœ¬æ”¯æŒ |
| `tool-input-start` | âš ï¸ | âš ï¸ | å·¥å…·è°ƒç”¨è¾“å…¥å¼€å§‹ | å¯èƒ½éœ€è¦æ”¹è¿› |
| `tool-input-delta` | âš ï¸ | âš ï¸ | å·¥å…·è°ƒç”¨è¾“å…¥å¢é‡ | æµ‹è¯•æœ‰é™ |
| `tool-input-available` | âš ï¸ | âš ï¸ | å·¥å…·è°ƒç”¨è¾“å…¥å®Œæˆ | å¯èƒ½éœ€è¦æ”¹è¿› |
| `tool-output-available` | âš ï¸ | âš ï¸ | å·¥å…·è°ƒç”¨è¾“å‡º | åŸºæœ¬æ”¯æŒ |
| `tool-output-error` | âš ï¸ | âš ï¸ | å·¥å…·è°ƒç”¨é”™è¯¯ | é”™è¯¯å¤„ç†æœ‰é™ |
| `reasoning` | âš ï¸ | âš ï¸ | æ¨ç†å†…å®¹ | å®éªŒæ€§åŠŸèƒ½ |
| `source-url` | âš ï¸ | âš ï¸ | æ¥æº URL å¼•ç”¨ | åŸºæœ¬å®ç° |
| `source-document` | âš ï¸ | âš ï¸ | æ¥æºæ–‡æ¡£ | åŸºæœ¬å®ç° |
| `file` | âš ï¸ | âš ï¸ | æ–‡ä»¶é™„ä»¶ | æ”¯æŒæœ‰é™ |
| `data` | âœ… | âœ… | è‡ªå®šä¹‰æ•°æ® | æ”¯æŒè‰¯å¥½ |
| `error` | âš ï¸ | âš ï¸ | é”™è¯¯æ¶ˆæ¯ | åŸºæœ¬é”™è¯¯å¤„ç† |
| `start-step` | âš ï¸ | âš ï¸ | æ­¥éª¤å¼€å§‹ | å®éªŒæ€§åŠŸèƒ½ |
| `finish-step` | âš ï¸ | âš ï¸ | æ­¥éª¤ç»“æŸ | å®éªŒæ€§åŠŸèƒ½ |
| `start` | âœ… | âœ… | æµå¼€å§‹ | æ”¯æŒè‰¯å¥½ |
| `finish` | âœ… | âœ… | æµç»“æŸ | æ”¯æŒè‰¯å¥½ |

**å›¾ä¾‹**ï¼šâœ… æ”¯æŒè‰¯å¥½ï¼Œâš ï¸ åŸºæœ¬/å®éªŒæ€§æ”¯æŒï¼ŒâŒ ä¸æ”¯æŒ

## ç¤ºä¾‹

### å®Œæ•´èŠå¤©åº”ç”¨

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_aisdk_adapter import LangChainAdapter
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

app = FastAPI()
llm = ChatOpenAI(model="gpt-4")

class ChatRequest(BaseModel):
    message: str
    protocol_version: str = "v4"

@app.post("/api/chat")
async def chat(request: ChatRequest):
    try:
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"),
            HumanMessage(content=request.message)
        ]
        
        stream = llm.astream_events(messages, version="v2")
        
        return LangChainAdapter.to_data_stream_response(
            stream=stream,
            options={
                "protocol_version": request.protocol_version,
                "auto_events": True
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### å·¥å…·é›†æˆç¤ºä¾‹

```python
from langchain_community.tools import DuckDuckGoSearchRun
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_aisdk_adapter import LangChainAdapter

# è®¾ç½®å·¥å…·å’Œä»£ç†
search = DuckDuckGoSearchRun()
tools = [search]
llm = ChatOpenAI(model="gpt-4")
agent = create_openai_functions_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

# ä½¿ç”¨å·¥å…·è°ƒç”¨è¿›è¡Œæµå¼å¤„ç†
stream = agent_executor.astream_events(
    {"input": "æœç´¢æœ€æ–°çš„ AI æ–°é—»"},
    version="v2"
)

data_stream = LangChainAdapter.to_data_stream(
    stream=stream,
    options={"protocol_version": "v5"}
)

async for chunk in data_stream:
    chunk_type = chunk.get("type")
    if chunk_type == "tool-input-available":
        print(f"å·¥å…·ï¼š{chunk.get('toolName')}")
        print(f"è¾“å…¥ï¼š{chunk.get('input')}")
    elif chunk_type == "tool-output-available":
        print(f"è¾“å‡ºï¼š{chunk.get('output')}")
```

## API å‚è€ƒ

### ç±»

- **`LangChainAdapter`**ï¼šä¸»é€‚é…å™¨ç±»
- **`DataStreamWithEmitters`**ï¼šå…·æœ‰æ‰‹åŠ¨å‘å°„æ–¹æ³•çš„æµ
- **`DataStreamResponse`**ï¼šFastAPI å“åº”åŒ…è£…å™¨
- **`DataStreamWriter`**ï¼šç”¨äºåˆå¹¶çš„æµå†™å…¥å™¨
- **`DataStreamContext`**ï¼šåŸºäºä¸Šä¸‹æ–‡çš„æµæ§åˆ¶
- **`ContextLifecycleManager`**ï¼šä¸Šä¸‹æ–‡ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **`BaseAICallbackHandler`**ï¼šåŸºç¡€å›è°ƒå¤„ç†å™¨
- **`ProtocolStrategy`**ï¼šåè®®ç­–ç•¥æ¥å£
- **`AISDKv4Strategy`**ï¼šAI SDK v4 å®ç°
- **`AISDKv5Strategy`**ï¼šAI SDK v5 å®ç°

### å‡½æ•°



## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼æœ¬é¡¹ç›®ä»å¤„äºæ—©æœŸå¼€å‘é˜¶æ®µï¼Œæœ‰è®¸å¤šæ–¹é¢å¯ä»¥æ”¹è¿›ï¼š

- æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œè¾¹ç¼˜æƒ…å†µè¦†ç›–
- æ›´å…¨é¢çš„æµ‹è¯•
- æ€§èƒ½ä¼˜åŒ–
- å¢å¼ºåè®®å…¼å®¹æ€§
- æ–‡æ¡£æ”¹è¿›
- å®é™…ä½¿ç”¨æ¡ˆä¾‹ç¤ºä¾‹

è¯·éšæ—¶æäº¤ Pull Request æˆ–å¼€å¯ issue è®¨è®ºæ”¹è¿›å»ºè®®ã€‚

## å…è´£å£°æ˜

æœ¬åº“æŒ‰ç°çŠ¶æä¾›ï¼Œå¯èƒ½æ— æ³•è¦†ç›–æ‰€æœ‰ä½¿ç”¨åœºæ™¯æˆ–è¾¹ç¼˜æƒ…å†µã€‚è™½ç„¶æˆ‘ä»¬åŠªåŠ›ä¸ AI SDK åè®®ä¿æŒå…¼å®¹ï¼Œä½†å¯èƒ½å­˜åœ¨å·®å¼‚æˆ–ç¼ºå¤±åŠŸèƒ½ã€‚å»ºè®®ç”¨æˆ·åœ¨ç‰¹å®šç¯å¢ƒä¸­è¿›è¡Œå……åˆ†æµ‹è¯•ï¼Œå¹¶å°†æ”¹è¿›è´¡çŒ®å›é¡¹ç›®ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## æ›´æ–°æ—¥å¿—

### v0.0.1a1
- åˆå§‹ alpha ç‰ˆæœ¬
- åŸºæœ¬æ”¯æŒ AI SDK v4 å’Œ v5 åè®®
- æ ¸å¿ƒé€‚é…å™¨åŠŸèƒ½ï¼ˆå®éªŒæ€§ï¼‰
- FastAPI é›†æˆï¼ˆåŸºæœ¬ï¼‰
- æ‰‹åŠ¨äº‹ä»¶å‘å°„åŠŸèƒ½
- æœ‰é™çš„å·¥å…·è°ƒç”¨æ”¯æŒ
- åŸºæœ¬å†…å®¹ç±»å‹å¤„ç†
- ç®€å•ä½¿ç”¨è·Ÿè¸ª